{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling the coloumns\n",
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3long\", \"fM3trans\", \"fAplha\", \"fDist\", \"class\"]\n",
    "file_name = \"magic04.data\"\n",
    "\n",
    "df = pd.read_csv(file_name, names = cols)\n",
    "df[\"class\"] = df[\"class\"].apply(lambda x: 1 if x == 'g' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datasets\n",
    "train, valid, test = np.split(df.sample(frac = 1), [int(0.6*len(df)), int(0.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling function\n",
    "#importing random over sampler\n",
    "def scale_dataset(dataframe, oversample = False):\n",
    "  x = dataframe[dataframe.columns[:-1]].values\n",
    "  y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  x = scaler.fit_transform(x)\n",
    "\n",
    "  if oversample:\n",
    "    ros = RandomOverSampler()\n",
    "    x, y = ros.fit_resample(x, y)\n",
    "\n",
    "  data = np.hstack((x, np.reshape(y, (-1, 1))))\n",
    "\n",
    "  return data, x, y\n",
    "\n",
    "train, x_train, y_train = scale_dataset(train, oversample = True)\n",
    "valid, x_valid, y_valid = scale_dataset(valid, oversample = False)\n",
    "test, x_test, y_test = scale_dataset(test, oversample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Implementation\n",
    "#importing kneigbour classifier\n",
    "#importing classification report\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74      1345\n",
      "           1       0.86      0.85      0.85      2459\n",
      "\n",
      "    accuracy                           0.81      3804\n",
      "   macro avg       0.79      0.80      0.80      3804\n",
      "weighted avg       0.81      0.81      0.81      3804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Implementation\n",
    "#importing GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model = nb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.40      0.51      1345\n",
      "           1       0.73      0.90      0.81      2459\n",
      "\n",
      "    accuracy                           0.72      3804\n",
      "   macro avg       0.71      0.65      0.66      3804\n",
      "weighted avg       0.71      0.72      0.70      3804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "#importing logistic regression\n",
    "\n",
    "logreg_model  = LogisticRegression()\n",
    "logreg_model = logreg_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      1345\n",
      "           1       0.84      0.82      0.83      2459\n",
      "\n",
      "    accuracy                           0.79      3804\n",
      "   macro avg       0.77      0.77      0.77      3804\n",
      "weighted avg       0.79      0.79      0.79      3804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "#import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model = svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1345\n",
      "           1       0.88      0.90      0.89      2459\n",
      "\n",
      "    accuracy                           0.86      3804\n",
      "   macro avg       0.84      0.84      0.84      3804\n",
      "weighted avg       0.85      0.86      0.86      3804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "#import tensorflow\n",
    "\n",
    "def train_model(x_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
    "    nn_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(num_nodes, activation=\"relu\", input_shape=(10,)),\n",
    "        tf.keras.layers.Dropout(dropout_prob),\n",
    "        tf.keras.layers.Dense(num_nodes, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(dropout_prob),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = nn_model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    return nn_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_val_loss = float('inf')\n",
    "least_loss_model = None\n",
    "epochs = 100\n",
    "for num_nodes in [16, 32, 64]:\n",
    "    for dropout_prob in [0, 0.2]:\n",
    "        for lr in [0.1, 0.005, 0.001]:\n",
    "            for batch_size in [32, 64, 128]:\n",
    "                model, history = train_model(x_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs)\n",
    "                val_loss = model.evaluate(x_valid, y_valid)[0]\n",
    "                if val_loss < least_val_loss:\n",
    "                    least_val_loss = val_loss\n",
    "                    least_loss_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = least_loss_model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5).astype(int).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.81      1345\n",
      "           1       0.87      0.94      0.91      2459\n",
      "\n",
      "    accuracy                           0.87      3804\n",
      "   macro avg       0.87      0.84      0.86      3804\n",
      "weighted avg       0.87      0.87      0.87      3804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
